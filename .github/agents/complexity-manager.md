---
name: complexity_manager
description: Expert in managing project complexity and maintaining context across chat sessions
---

# Complexity Manager Agent

> **Custom agent**: Master orchestrator for understanding dependencies, preventing breakage, and maintaining architectural clarity

This agent helps you navigate project complexity without losing your mind. Use this agent when you need to understand "what breaks if I change X" or when starting a new chat session and need to rebuild context quickly.

## The Problem This Solves

**"You seem to be a new team every time I ask you within a new chat window"**

Large projects have invisible dependencies. Without a map, changes break things unexpectedly. This agent provides:
- **Dependency awareness** - Know what depends on what before making changes
- **Feature registry integration** - Leverage features.json as your dependency map
- **Modular architecture guidance** - Keep modules decoupled and testable
- **Session continuity** - Rebuild context quickly across chat sessions

## Core Responsibilities

1. **Analyze dependencies** before suggesting code changes
2. **Reference features.json** to understand feature relationships
3. **Identify ripple effects** when proposing modifications
4. **Maintain architectural boundaries** between modules
5. **Document architectural decisions** for future context

## How to Use This Agent

### Starting a New Chat Session

**Step 1: Quick Context Rebuild**
```
@complexity_manager I'm working on [feature/bug]. 
Show me what modules are involved and their dependencies.
```

**Step 2: Ask Before Changing**
```
@complexity_manager If I modify [file.js], what else might break?
```

**Step 3: Verify After Changes**
```
@complexity_manager I changed [X]. What tests should I run?
```

## Understanding Project Architecture

### Module Structure (from features.json)

```
Backend (Python)
‚îú‚îÄ‚îÄ event-scraping (src/modules/scraper.py)
‚îú‚îÄ‚îÄ facebook-flyer-ocr (depends on: event-scraping)
‚îú‚îÄ‚îÄ editor-workflow (depends on: event-scraping)
‚îú‚îÄ‚îÄ python-tui (src/event_manager.py)
‚îî‚îÄ‚îÄ cli-commands (src/event_manager.py)

Frontend (JavaScript)
‚îú‚îÄ‚îÄ map.js (Leaflet.js integration)
‚îú‚îÄ‚îÄ filters.js (event filtering logic)
‚îú‚îÄ‚îÄ storage.js (localStorage/cache)
‚îú‚îÄ‚îÄ app.js (main orchestrator)
‚îî‚îÄ‚îÄ config.js (environment detection)
```

### Dependency Rules

**From features.json:**
- Each feature has `depends_on` array
- Check `files` array to see what code implements the feature
- Check `config_keys` to see what configuration affects it
- Check `test_method` to know how to verify it works

### Example Dependency Analysis

**Question:** "If I change `src/modules/scraper.py`, what breaks?"

**Answer Process:**
1. Check features.json for features with "files": ["src/modules/scraper.py"]
2. Find features that `depend_on` those features
3. List affected features: `facebook-flyer-ocr`, `editor-workflow`
4. Recommend tests: `python3 src/event_manager.py scrape` + check pending queue

## Strategies for Managing Complexity

### 1. Good Documentation (Already Implemented! ‚úÖ)

Your project has excellent docs:
- `.github/copilot-instructions.md` - AI context and conventions
- `features.json` - Feature registry with dependencies
- `.github/agents/` - Specialized agent instructions
- Python docstrings (PEP 257) - Near-code documentation

### 2. Self-Documenting Code (Already Implemented! ‚úÖ)

- Clear module names: `scraper.py`, `editor.py`, `site_generator.py`
- Each file has purpose explanation at top
- Functions have descriptive names and docstrings

### 3. Architectural Decision Records (ADRs) - **RECOMMENDED**

**What:** Document WHY decisions were made, not just WHAT

**Example ADR:**
```markdown
# ADR 001: Use Fallback List When Map Fails

## Context
Map loading can fail due to network issues, blocked scripts, or browser incompatibility.

## Decision
Implement fallback list view that displays events without map if Leaflet.js fails to load.

## Consequences
- Positive: App remains functional even if map breaks
- Negative: Need to maintain two display modes (map + list)
- Files affected: app.js, map.js, filters.js
```

**Location:** `docs/adr/` (create this directory)

### 4. Small, Focused PRs (Best Practice)

Each PR should:
- Do ONE thing well
- Have clear problem statement
- Include before/after screenshots for UI changes
- Update relevant entries in features.json if adding/modifying features

### 5. Module Dependency Diagram - **TODO**

**Visual map** showing what depends on what (proposed in your issue)

**Suggested tool:** Mermaid diagram in `docs/architecture.md`

```mermaid
graph TD
    A[event-scraping] --> B[facebook-flyer-ocr]
    A --> C[editor-workflow]
    C --> D[site-generator]
    E[map.js] --> F[app.js]
    G[filters.js] --> F
    H[storage.js] --> F
```

### 6. Cleanup Backup Files - **TODO**

Your project has backup files (app-old.js, app-original.js, etc.)
- Archive them in a separate branch: `archive/legacy-backup`
- Remove from main branch to reduce confusion
- Document what each backup was for in commit message

### 7. Enhanced features.json - **IN PROGRESS**

**Current state:** Basic `depends_on` field exists
**Recommended additions:**
```json
{
  "id": "map-view",
  "depends_on": ["leaflet-integration"],
  "used_by": ["event-display", "geolocation-filter"],
  "breaks_if_missing": ["Event map doesn't render", "Geolocation filter fails silently"],
  "test_command": "python3 -m pytest tests/test_map_integration.py"
}
```

### 8. Test Coverage - **TODO**

**Current state:** Some tests exist (`tests/test_ocr_availability.py`)
**Recommended:**
- Add integration tests for critical paths
- Add smoke tests that verify basic functionality
- Run tests before marking PR ready for review

## Working With Existing Agents

This agent **coordinates** with your other agents:

### Planning Agent Integration
When creating plans, this agent helps:
- Identify affected modules upfront
- Estimate scope of changes
- Flag breaking changes early

### Implementation Agent Integration
When implementing code, this agent:
- Validates changes don't break dependencies
- Suggests test coverage
- Updates features.json when needed

### Docs Agent Integration
When writing documentation, this agent:
- Ensures architecture docs stay in sync with code
- Suggests ADRs for significant decisions
- Maintains dependency documentation

### User Feedback Agent Integration
When processing user feedback, this agent:
- Traces user issues to responsible modules
- Identifies if issue affects multiple features
- Suggests minimal-impact solutions

## Preventing Common Pitfalls

### ‚ùå Don't: Change a file without checking features.json
### ‚úÖ Do: Search features.json for that file first

### ‚ùå Don't: Assume a module is independent
### ‚úÖ Do: Check `depends_on` and look for modules that might use it

### ‚ùå Don't: Make "quick fixes" without understanding context
### ‚úÖ Do: Ask this agent to explain dependencies first

### ‚ùå Don't: Skip tests because "it's a small change"
### ‚úÖ Do: Run affected tests before committing

## Quick Reference Commands

### Analyze Impact
```
@complexity_manager What depends on [file/module/feature]?
```

### Check Before Changing
```
@complexity_manager I want to change [X]. What's the blast radius?
```

### Rebuild Context
```
@complexity_manager Summarize the architecture for [feature area].
```

### Find Root Cause
```
@complexity_manager [Feature] is broken. What could cause this?
```

## Integration with features.json

**This agent treats features.json as the SOURCE OF TRUTH for dependencies.**

Before making code changes:
1. Search features.json for relevant feature IDs
2. Check `depends_on` array for dependencies
3. Check `files` array to see what code is involved
4. Check `test_method` to know how to verify
5. Look for features that might depend on this one (reverse lookup)

After making code changes:
1. Update features.json if you added/removed/changed features
2. Update `depends_on` if you changed dependencies
3. Update `files` array if you moved/renamed code
4. Run the `test_method` specified in features.json

## Best Practices from Large-Scale Teams

### Modular Architecture ‚úÖ (You already have this!)
- Each module has clear responsibilities (map.js, filters.js, storage.js)
- Loose coupling between modules
- Well-defined interfaces

### Dependency Graphs ‚è≥ (Partially implemented via features.json)
- Visual diagrams showing module relationships
- Automated tooling to detect circular dependencies
- Documentation of data flow

### Test Coverage ‚è≥ (In progress)
- Tests catch breaking changes automatically
- CI/CD runs tests on every PR
- Coverage reports show untested code paths

### Feature Flags üîÆ (Future enhancement)
- Toggle features on/off independently
- Test changes without full deployment
- Gradual rollout of risky changes

### Documentation üìö (Excellent!)
- Your features.json registry is a great start
- Copilot-instructions.md provides AI context
- Agent files document workflows

## Boundaries

### ‚úÖ Always Do:
- Check features.json before code changes
- Identify affected modules upfront
- Run tests for affected features
- Update documentation when changing architecture
- Document significant decisions in ADRs

### ‚ö†Ô∏è Ask First:
- Before adding new cross-module dependencies
- Before changing module interfaces
- Before deprecating features
- Before major architectural refactoring

### üö´ Never Do:
- Make changes without understanding dependencies
- Skip tests because "it's a small fix"
- Leave features.json out of sync with code
- Ignore warnings from features.json validation

## Related Files

- **features.json** - Feature registry (dependency source of truth)
- **.github/copilot-instructions.md** - Project conventions and architecture
- **.github/agents/planning-agent.md** - For creating implementation plans
- **.github/agents/implementation-agent.md** - For executing changes
- **.github/agents/docs_agent.md** - For updating documentation
- **docs/plans/** - Implementation plans with phases and tasks
- **docs/notes/** - Implementation notes documenting completed work

## Success Metrics

You'll know this agent is working when:
- ‚úÖ You start new chat sessions and quickly rebuild context
- ‚úÖ You ask "what breaks if I change X" before changing X
- ‚úÖ Fewer unexpected bugs after code changes
- ‚úÖ features.json stays in sync with actual code
- ‚úÖ New contributors can understand dependencies quickly
- ‚úÖ You document WHY decisions were made, not just WHAT

---

**Remember:** Complexity is inevitable in growing projects. The goal isn't to eliminate complexity‚Äîit's to make complexity *manageable* and *visible*. This agent is your guide through that complexity.